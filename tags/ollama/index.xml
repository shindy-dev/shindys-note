<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Ollama on Shindy's Note</title><link>https://shindy-dev.github.io/shindys-note/tags/ollama/</link><description>Recent content in Ollama on Shindy's Note</description><image><title>Shindy's Note</title><url>https://shindy-dev.github.io/favicon.ico</url><link>https://shindy-dev.github.io/favicon.ico</link></image><generator>Hugo -- 0.148.2</generator><language>ja</language><lastBuildDate>Fri, 15 Aug 2025 20:41:20 +0000</lastBuildDate><atom:link href="https://shindy-dev.github.io/shindys-note/tags/ollama/index.xml" rel="self" type="application/rss+xml"/><item><title>ObsidianでローカルLLMを使う</title><link>https://shindy-dev.github.io/shindys-note/posts/obsidian%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%ABlmm%E3%82%92%E4%BD%BF%E3%81%86/</link><pubDate>Fri, 15 Aug 2025 20:41:20 +0000</pubDate><guid>https://shindy-dev.github.io/shindys-note/posts/obsidian%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%ABlmm%E3%82%92%E4%BD%BF%E3%81%86/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Obsidianの拡張機能と&lt;a href="https://huggingface.co/">Hugging Face&lt;/a>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>、&lt;a href="https://ollama.com/">Ollama&lt;/a>&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>を使用してオフライン環境下での生産性の爆上げを図る。&lt;br>
※自己責任で実施すること。&lt;/p>
&lt;pre class="mermaid" style="background-color: white;">
flowchart LR
A(Hugging FaceでLLMをフォーク) --&amp;gt; B(OllamaでLLMをpull&amp;amp;ローカル実行)
B --&amp;gt; C(Obsidianの拡張機能でLLMを実行)
&lt;/pre>
&lt;p>ちなみに表題に反して、おすすめはGemini APIです。&lt;/p>
&lt;h2 id="実装環境">実装環境&lt;/h2>
&lt;p>M3 Macbook&lt;/p>
&lt;h2 id="hugging-faceでllmをフォーク">Hugging FaceでLLMをフォーク&lt;/h2>
&lt;p>自分の使いたいLLMがいつ配信停止となっても困らないように、自分のリポジトリにフォークする。&lt;br>
※ライセンスには注意し、自己責任で行うこと
※Hugging FaceにはOllamaで使えない形式のモデルも存在するため選定の際は注意すること。&lt;br>
※いつ配信停止となっても別のモデルを探せるのであれば&lt;a href="#Ollama%E3%81%A7LLM%E3%82%92pull%EF%BC%86%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E5%AE%9F%E8%A1%8C">OllamaでLLMをpull＆ローカル実行&lt;/a>から実施すること。&lt;/p>
&lt;h3 id="hugging-face-アカウント-の作成">Hugging Face アカウント の作成&lt;/h3>
&lt;p>Hugging Faceのアカウントはメールアドレスがあれば作れる。有料プランを使用する場合は乗っ取り防止で2FAの設定をしておいた方がいい。&lt;br>
&lt;a href="https://huggingface.co/">Hugging Face – The AI community building the future.&lt;/a>&lt;/p>
&lt;h3 id="hugging-face-cli-のインストール">Hugging Face CLI のインストール&lt;/h3>
&lt;p>Hugging FaceのGUIだと日本語対応しておらず、UIも変更される可能性もあるため、再現性を確保するためCLIをインストールする。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">brew install huggingface-cli
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="access-tokens-の作成">Access Tokens の作成&lt;/h3>
&lt;p>Settingsの[Access Tokens](&lt;a href="https://huggingface.co/settings/tokens">Hugging Face – The AI community building the future.&lt;/a>)から作成する。Repositories内の項目をチェックする。トークンは発行時にしか表示されないため、メモしておくこと。
&lt;img alt="600" loading="lazy" src="../../assets/Pasted%20image%2020250816215531.png">&lt;/p>
&lt;h3 id="hugging-face-cli-でログイン">Hugging Face CLI でログイン&lt;/h3>
&lt;p>先ほど発行したトークンでログインする。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">hf auth login --token &amp;lt;トークン&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="git-の大容量ファイル対応">Git の大容量ファイル対応&lt;/h3>
&lt;p>gitが大規模言語モデル等の大容量ファイルを操作できるように&lt;code>git-lfs&lt;/code>をインストールする。&lt;/p></description></item></channel></rss>